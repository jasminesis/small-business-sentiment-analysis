---
title: "Classifying review data"
format: pdf
execute:
  cache: true
---

# Load libraries

```{r}
library(tidyverse)
library(tidytext)
library(jsonlite)
library(ggmap)
library(geomtextpath) # for geom_textvline

setwd("~/Documents/GitHub/small-business-sentiment-analysis/scripts")

source("ggplot_settings.R")
theme_set(theme_custom())
```


# Load metadata and review data

```{r load_data, cache.lazy = FALSE}
# loads `metadata` which is metadata of all reviews
load("../review_data/metadata.RData")

# load `reviews` which has all the 2019, 2020 and 2021 reviews
load("../review_data/reviews19_20_21.RData")

# load `combined_reviews` which has all the 2019, 2020 and 2021 reviews for Asian, Mexican, and pizza places
load("../review_data/combined_reviews.RData")

reviews_with_sentiment <- read_csv("../review_data/reviews_with_sentiment.csv")
```

# Combine with minority-owned business data (not just restaurants)

```{r eval=F}
small_businesses <- read_csv("../review_data/SBS_Certified_Business_List_20240309.csv")
small_businesses$name <- small_businesses$Vendor_Formal_Name
small_businesses <- small_businesses |> select(name, First_Name, Last_Name, Business_Description, Ethnicity)

joined <- inner_join(small_businesses, metadata)
# 67 common establishments between the two!

asian_gmap_ids <- joined |>
  filter(Ethnicity == "ASIAN") |>
  pull(gmap_id)

# 2,383 rows for ASIAN
small_businesses |> filter(Ethnicity == "ASIAN")

# d |> filter(gmap_id %in% asian_gmap_ids)
```

# Combine and select asian, mexican and pizza restaurants

```{r eval=F}
# join review and cuisines to get smaller list of only asian restaurants
asian <- read_csv("../review_data/nyc_asian_restaurant.csv") |>
  select(name, alias, categories, coordinates, location)
asian <- inner_join(metadata, asian, by = "name") |>
  distinct(gmap_id, .keep_all = TRUE)
# 440 rows after only keeping the first by name
# 533 rows after only keeping the first by gmap_id

d_asian <- inner_join(reviews, asian, by = "gmap_id") |>
  bind_cols(type = "asian")
# 113,116 for 2019, 2020 and 2021


# NOTE: SOPHIA LOOK HERE
# repeat for mexican and pizza restaurants
pizza <- read_csv("../review_data/nyc_pizza_restaurant.csv") |>
  select(name, alias, categories, coordinates, location)
pizza <- inner_join(metadata, pizza, by = "name") |>
  distinct(gmap_id, .keep_all = TRUE)
d_pizza <- inner_join(reviews, pizza, by = "gmap_id") |>
  bind_cols(type = "pizza")

mex <- read_csv("../review_data/nyc_mexican_restaurant.csv") |>
  select(name, alias, categories, coordinates, location)
mex <- inner_join(metadata, mex, by = "name") |>
  distinct(gmap_id, .keep_all = TRUE)
d_mex <- inner_join(reviews, mex, by = "gmap_id") |>
  bind_cols(type = "mexican")

combined_reviews <- bind_rows(d_asian, d_pizza, d_mex) |>
  mutate(date = as.Date(paste(year, month, 01), "%Y %m %d")) |>
  filter(time <= as.Date(paste(2021, 06, 01), "%Y %m %d"))
# save(combined_reviews, file = "../review_data/combined_reviews.RData")
```

## Plotting

```{r exploratory_data_viz}
covid_start <- as.Date(paste(2020, 03, 15), "%Y %m %d")
stopah_start <- as.Date(paste(2021, 03, 11), "%Y %m %d")

ggplot(d_asian, aes(x = time, y = rating)) +
  geom_jitter() +
  labs(x = "date", title = "Ratings vs date for Asian restaurants")

# combined_reviews |>
#   filter(type == "asian") |>
#   group_by(gmap_id, month, year) |>
#   summarize(mean_rating = mean(rating)) |>
#   mutate(date = as.Date(paste(year, month, 01), "%Y %m %d")) |>
#   ggplot(aes(x = date, y = mean_rating, color = gmap_id)) +
#   geom_line()+
#   theme(legend.position = "none") +
#   labs(title = "Average rating in a month for each Asian restaurant")
# messy plot - no real trend

combined_reviews |>
  count(date) |>
  ggplot(aes(x = date, y = n)) +
  geom_bar(stat = "identity", fill = "darkslategray") +
  geom_textvline(label = "COVID-19", vjust = 1.5, hjust = 1, size = 3, xintercept = covid_start, color = "indianred2", lty = "dashed") +
  geom_textvline(label = "Stop AAPI Hate", vjust = 1.5, hjust = 1, size = 3, xintercept = stopah_start, color = "dodgerblue2", lty = "dashed") +
  labs(title = "Total count of reviews for all restaurants", x = "Date", y = "Count")

# combined_reviews |>
#   filter(type == "asian") |>
#   group_by(gmap_id, month, year, rating) |>
#   mutate(date = as.Date(paste(year, month, 01), "%Y %m %d")) |>
#   ggplot(aes(x = date)) +
#   geom_vline(xintercept = covid_start, color = "indianred2", lty = "dashed") +
#   geom_vline(xintercept = stopah_start, color = "dodgerblue2", lty = "dashed") +
#   geom_density() +
#   facet_wrap(vars(rating)) +
#   labs(title = "Ratings over time for Asian restaurants")

# combined_reviews |>
#   filter(type == "pizza") |>
#   group_by(gmap_id, month, year, rating) |>
#   mutate(date = as.Date(paste(year, month, 01), "%Y %m %d")) |>
#   ggplot(aes(x = date)) +
#   geom_textvline(xintercept = covid_start, color = "indianred2", lty = "dashed", label = "COVID-19") +
#   geom_vline(xintercept = stopah_start, color = "dodgerblue2", lty = "dashed") +
#   geom_density() +
#   facet_wrap(vars(rating)) +
#   labs(title = "Ratings over time for pizza restaurants")

combined_reviews |>
  mutate(type = factor(type, levels = c("pizza", "mexican", "asian"))) |>
  mutate(date = as.Date(paste(year, month, 01), "%Y %m %d")) |>
  ggplot(aes(x = date, fill = type)) +
  geom_density(color = "gray95", alpha = 0.7) +
  geom_vline(xintercept = covid_start, color = "indianred2", lty = "dashed") +
  geom_vline(xintercept = stopah_start, color = "dodgerblue2", lty = "dashed") +
  facet_wrap(vars(rating)) +
  labs(title = "Ratings over time for Asian and Mexican restaurants", fill = "Cuisine", x = "Date") +
  theme(axis.text.x = element_blank())

combined_reviews |>
  mutate(type = factor(str_to_title(type), levels = c("Asian", "Mexican", "Pizza"))) |>
  group_by(type, month, year) |>
  summarise(mean_rating = mean(rating)) |>
  mutate(date = as.Date(paste(year, month, 01), "%Y %m %d")) |>
  ggplot(aes(x = date, y = mean_rating, color = type)) +
  geom_line() +
  geom_point() +
  scale_color_manual(values = c("lightpink", "steelblue", "darkseagreen")) +
  geom_vline(xintercept = covid_start, color = "indianred2", lty = "dashed") +
  geom_vline(xintercept = stopah_start, color = "dodgerblue2", lty = "dashed") +
  labs(title = "Average ratings over time for Asian, Mexican and pizza restaurants", color = "Cuisine", x = "Date", y = "Mean rating")
ggsave("../figures/average_ratings.png", width = 8, height = 5)
```

## did people get more unhappy with asian restaurants, and did they get less unhappy over the campaign 

```{r}
# trying to answer whether the drop for asian restaurants is more or the same for pizza/mexican
# proportion of 1 star reviews over all reviews
combined_reviews |>
  filter(type == "asian" | type == "mexican") |>
  # filter(type == "mexican") |>
  count(rating, date, type) |>
  group_by(date, type) |>
  mutate(prop = prop.table(n)) |>
  arrange(date) |>
  filter(rating == 1) |>
  ggplot() +
  geom_vline(xintercept = covid_start, color = "red", lty = "dashed") +
  geom_vline(xintercept = stopah_start, color = "blue", lty = "dashed") +
  geom_point(aes(x = date, y = prop, color = type)) +
  # geom_point(aes(x = date, y = prop, color = as.factor(rating))) +
  labs(title = "Proportion of 1 star reviews over all reviews", x = "Date", y = "Proportion")

combined_reviews |>
  filter(type == "asian", month == "04", year == "2020", rating < 3, !is.na(text)) |>
  pull(text) |>
  sample(10)
```


## Sentiment analysis

```{r sentiment_analysis, eval=F}
review_text <- unnest_tokens(d_asian, word, text)

lexicon <- tidytext::get_sentiments("bing")
# remove the double rows for this word so that inner_join works
lexicon <- lexicon |> filter(!(word %in% c("envious", "enviously", "enviousness")))

review_stm <- review_text |>
  group_by(time, gmap_id) |>
  inner_join(lexicon, by = "word") |>
  mutate(score = ifelse(sentiment == "negative", 0, 1))

mean_stm <- review_stm |>
  group_by(time, gmap_id) |>
  summarize(mean_sentiment = mean(score, na.rm = T), mean_rating = mean(rating))

ggplot(mean_stm, aes(x = mean_rating, y = mean_sentiment)) +
  geom_point()
# sentiment aligns with rating? not really
# Doesn't show anything interesting
```


## Plot restaurants by coordinates

```{r}
restaurant_locations <- combined_reviews |>
  distinct(gmap_id, .keep_all = TRUE) |>
  select(-time, -rating, -text, -month, -year, -date) |>
  rowwise() |>
  mutate(
    # coordinates had the wrong quote marks for JSON parsing using from JSON
    # have to substitute
    coordinates = gsub('["{*}"]', "", coordinates),
    coordinates = gsub("'", '"', coordinates),
    coordinates = paste0("{", coordinates, "}"),
    lat = fromJSON(coordinates)$latitude,
    lon = fromJSON(coordinates)$longitude,
    zipcode = as.numeric(substr(address, (nchar(address) - 5 + 1), nchar(address)))
  ) |>
  filter(!is.na(zipcode))
# write_csv(restaurant_locations, file = "../review_data/restaurant_locations_by_type.csv")


register_google(key = read_lines("../google-api-key"))
nyc_map_12 <- qmap("new-york-city", color = "bw", zoom = 12)

# nyc_map <- qmap("new-york-city", color = "bw", zoom=11)
pd_asian <- restaurant_locations |>
  filter(type == "asian") |>
  group_by(lat, lon) |>
  summarize(n = n())
pd_asian_zip <- restaurant_locations |>
  filter(type == "asian") |>
  group_by(zipcode) |>
  summarize(lat = mean(lat), lon = mean(lon), n = n())

nyc_map_12 + geom_point(
  data = pd_asian, aes(x = lon, y = lat, size = n),
  show.legend = T, col = alpha("hotpink4", 0.4)
) + labs(title = "Geographic location of Asian restaurants")
nyc_map_12 + geom_point(
  data = pd_asian_zip, aes(x = lon, y = lat, size = n),
  show.legend = T, col = alpha("hotpink4", 0.4)
) + labs(title = "Geographic location of Asian restaurants", subtitle = "Clustered by zip code")

pd <- restaurant_locations |>
  filter(type == "pizza") |>
  group_by(lat, lon) |>
  summarize(n = n())

nyc_map_12 + geom_point(data = pd, aes(x = lon, y = lat, size = n), show.legend = FALSE, col = alpha("hotpink4", 0.4)) + labs(title = "Geographic location of Pizza restaurants")
```

# see if there's a spike in racist reviews?????
BUT HOW!??!?!!

## Work with polarity and subjectivity

```{r}
# average polarity and subjectivity by restaurant
d <- reviews_with_sentiment |>
  mutate(date = as.Date(paste(year, month, 01), "%Y %m %d")) |>
  group_by(name, date) |>
  mutate(
    avg_polarity = mean(polarity, na.rm = TRUE),
    avg_subjectivity = mean(subjectivity, na.rm = TRUE)
  ) |>
  select(name, avg_polarity, avg_subjectivity) |>
  unique()

d <- d |>
  ungroup() |>
  mutate(
    scaled_avg_polarity = scale(avg_polarity)[, 1],
    scaled_avg_subjectivity = scale(avg_subjectivity)[, 1]
  )

d |>
  pivot_longer(starts_with("scaled"), names_to = "property", values_to = "value") |>
  select(name, property, value) |>
  ggplot() +
  geom_density(aes(value, color = property)) +
  labs(title = "Average polarity and\nsubjectivity for Asian restaurants")
```

- facet by review score

If doing a nested model, certain restaurants are gonna have an outsized impact - might wanna have random intercepts

Conditioned on similar review scores, does polarity and subjectivity change? 


```{r gam}
library(mgcv)

covid_start <- as_date("2020-03-15")

asn_sentiment <- read_csv("../sentiment_data/asian_sentiment.csv") |> mutate(
  prepost_covid = as_date(time) - covid_start,
  rating = as.numeric(rating),
  prepost_covid = as.numeric(prepost_covid)
)

# gams_asn <- mgcv::gam(polarity ~ 1 + s(rating, prepost_covid), data = asn_sentiment)

gams_asn <- mgcv::gam(polarity ~ 1 + te(rating, prepost_covid, k = c(4, 10)), data = asn_sentiment)
# setting c(4, 10) means that it fits the points but is still smooth
# really flat ones was because there were only 2 (ish?) knots allowed
# now it allows 4 knots for rating
# now it allows 10 knots for date - stitching together 10 or 11 cubic functions for date
# why use `te()`? because it's one that allows for interaction between two factors
# `s()` is for just one variable

new_dat <- data.frame(prepost_covid = rep(-450:550, each = 5), rating = 1:5)
new_dat$pred <- predict(gams_asn, newdata = new_dat)

ggplot(new_dat, aes(x = prepost_covid, y = pred, color = as.factor(rating))) +
  geom_line()

ggplot(asn_sentiment, aes(x = as.factor(rating), y = polarity, fill = as.factor(rating))) +
  geom_violin()
```

GAM allows us to see differences in sentiment that have already accounted for rating.
